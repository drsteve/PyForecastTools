<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>PyForecastTools - Model Validation and Forecast Verification &mdash; PyForecastTools 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="PyForecastTools 1.0 documentation" href="index.html" />
    <link rel="prev" title="PyForecastTools documentation" href="index.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="pyforecasttools-model-validation-and-forecast-verification">
<h1>PyForecastTools - Model Validation and Forecast Verification<a class="headerlink" href="#pyforecasttools-model-validation-and-forecast-verification" title="Permalink to this headline">¶</a></h1>
<div class="section" id="verify-core-metrics-and-classes">
<h2>Verify - Core metrics and classes<a class="headerlink" href="#verify-core-metrics-and-classes" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference internal" href="#metrics">Metrics</a></li>
<li><a class="reference internal" href="#contingency-tables">Contingency Tables</a></li>
</ul>
<div class="section" id="metrics">
<h3>Metrics<a class="headerlink" href="#metrics" title="Permalink to this headline">¶</a></h3>
<p class="rubric">Functions</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#verify.skill" title="verify.skill"><code class="xref py py-obj docutils literal"><span class="pre">skill</span></code></a>(A_data,&nbsp;A_ref[,&nbsp;A_perf])</td>
<td>Generic forecast skill score formulation for quantification of forecast improvement</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.percBetter" title="verify.percBetter"><code class="xref py py-obj docutils literal"><span class="pre">percBetter</span></code></a>(predict1,&nbsp;predict2,&nbsp;observed)</td>
<td>The percentage of cases when method A was closer to actual than method B</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#verify.bias" title="verify.bias"><code class="xref py py-obj docutils literal"><span class="pre">bias</span></code></a>(predicted,&nbsp;observed)</td>
<td>Scale-dependent bias as measured by the mean error</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.meanPercentageError" title="verify.meanPercentageError"><code class="xref py py-obj docutils literal"><span class="pre">meanPercentageError</span></code></a>(predicted,&nbsp;observed)</td>
<td>Order-dependent bias as measured by the mean percentage error</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#verify.medianLogAccuracy" title="verify.medianLogAccuracy"><code class="xref py py-obj docutils literal"><span class="pre">medianLogAccuracy</span></code></a>(predicted,&nbsp;observed[,&nbsp;...])</td>
<td>Order-dependent bias as measured by the median of the log accuracy ratio</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.symmetricSignedBias" title="verify.symmetricSignedBias"><code class="xref py py-obj docutils literal"><span class="pre">symmetricSignedBias</span></code></a>(predicted,&nbsp;observed)</td>
<td>Symmetric signed bias, expressed as a percentage</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#verify.accuracy" title="verify.accuracy"><code class="xref py py-obj docutils literal"><span class="pre">accuracy</span></code></a>(data[,&nbsp;climate])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.medSymAccuracy" title="verify.medSymAccuracy"><code class="xref py py-obj docutils literal"><span class="pre">medSymAccuracy</span></code></a>(predicted,&nbsp;observed[,&nbsp;mfunc,&nbsp;...])</td>
<td>Median Symmetric Accuracy: Scaled measure of accuracy that is not biased to over- or under-predictions.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#verify.meanSquaredError" title="verify.meanSquaredError"><code class="xref py py-obj docutils literal"><span class="pre">meanSquaredError</span></code></a>(data[,&nbsp;climate])</td>
<td>Calculate the mean squared error of a data set relative to some reference value</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.RMSE" title="verify.RMSE"><code class="xref py py-obj docutils literal"><span class="pre">RMSE</span></code></a>(data[,&nbsp;climate])</td>
<td>Calculate the root mean squared error of a data set relative to some reference value</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">meanAPE</span></code>(predicted,&nbsp;observed[,&nbsp;mfunc])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.meanAbsError" title="verify.meanAbsError"><code class="xref py py-obj docutils literal"><span class="pre">meanAbsError</span></code></a>(data[,&nbsp;climate])</td>
<td>Calculate the mean absolute error of a data set relative to some reference value</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#verify.medAbsError" title="verify.medAbsError"><code class="xref py py-obj docutils literal"><span class="pre">medAbsError</span></code></a>(data[,&nbsp;climate])</td>
<td>Calculate the median absolute error of a data set relative to some reference value</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.scaledAccuracy" title="verify.scaledAccuracy"><code class="xref py py-obj docutils literal"><span class="pre">scaledAccuracy</span></code></a>(predicted,&nbsp;observed)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#verify.nRMSE" title="verify.nRMSE"><code class="xref py py-obj docutils literal"><span class="pre">nRMSE</span></code></a>(predicted,&nbsp;observed)</td>
<td>Calculate the normalized root mean squared error of a data set relative to some reference value</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="contingency-tables">
<h3>Contingency Tables<a class="headerlink" href="#contingency-tables" title="Permalink to this headline">¶</a></h3>
<p class="rubric">Classes</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#verify.ContingencyNxN" title="verify.ContingencyNxN"><code class="xref py py-obj docutils literal"><span class="pre">ContingencyNxN</span></code></a></td>
<td>Class to work with NxN contingency tables for forecast verification</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#verify.Contingency2x2" title="verify.Contingency2x2"><code class="xref py py-obj docutils literal"><span class="pre">Contingency2x2</span></code></a></td>
<td>Class to work with 2x2 contingency tables for forecast verification</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-verify">
<span id="function-class-documentation"></span><h3>Function/Class Documentation<a class="headerlink" href="#module-verify" title="Permalink to this headline">¶</a></h3>
<p>Module containing verification and performance metrics</p>
<p>Author: Steve Morley
Institution: Los Alamos National Laboratory
Contact: <a class="reference external" href="mailto:smorley&#37;&#52;&#48;lanl&#46;gov">smorley<span>&#64;</span>lanl<span>&#46;</span>gov</a>
Los Alamos National Laboratory</p>
<p>Copyright (c) 2017, Los Alamos National Security, LLC
All rights reserved.</p>
<dl class="class">
<dt id="verify.Contingency2x2">
<em class="property">class </em><code class="descclassname">verify.</code><code class="descname">Contingency2x2</code><a class="headerlink" href="#verify.Contingency2x2" title="Permalink to this definition">¶</a></dt>
<dd><p>Class to work with 2x2 contingency tables for forecast verification</p>
<p>The table is defined following the standard presentation in works such 
as Wilks [2006], where the columns are observations and the rows are 
predictions. For a binary forecast, this gives a table</p>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="7%" />
<col width="36%" />
<col width="36%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td colspan="2" rowspan="2">&nbsp;</td>
<td colspan="2">Observed</td>
</tr>
<tr class="row-even"><td>Y</td>
<td>N</td>
</tr>
<tr class="row-odd"><td rowspan="2">Predicted</td>
<td>Y</td>
<td>True Positive</td>
<td>False Positive</td>
</tr>
<tr class="row-even"><td>N</td>
<td>False Negative</td>
<td>True Negative</td>
</tr>
</tbody>
</table>
<p>Note that in many machine learning applications this table is called a
<a href="#id1"><span class="problematic" id="id2">``</span></a>confusion matrix&#8217;&#8217; and the columns and rows are often transposed.</p>
<p>Wilks, D.S. (2006), Statistical Methods in the Atmospheric Sciences, 2nd Ed.
Academic Press, Elsevier, Burlington, MA.</p>
<p>Duplicating the Finley[1884] tornado forecasts [Wilks, 2006, pp267-268]</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">verify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span> <span class="o">=</span> <span class="n">verify</span><span class="o">.</span><span class="n">Contingency2x2</span><span class="p">([[</span><span class="mi">28</span><span class="p">,</span><span class="mi">72</span><span class="p">],[</span><span class="mi">23</span><span class="p">,</span><span class="mi">2680</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="go">2803</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">threat</span><span class="p">()</span>
<span class="go">0.22764227642276422</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">heidke</span><span class="p">()</span>
<span class="go">0.35532486145845693</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">peirce</span><span class="p">()</span>
<span class="go">0.52285681714546284</span>
</pre></div>
</div>
<dl class="method">
<dt id="verify.Contingency2x2.FAR">
<code class="descname">FAR</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.FAR" title="Permalink to this definition">¶</a></dt>
<dd><p>False Alarm Ratio, the fraction of incorrect &#8220;yes&#8221; forecasts</p>
<dl class="docutils">
<dt>far <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The false alarm ratio of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.MatthewsCC">
<code class="descname">MatthewsCC</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.MatthewsCC" title="Permalink to this definition">¶</a></dt>
<dd><p>Matthews Correlation Coefficient</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">event_series</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">True</span><span class="p">,</span>  <span class="bp">True</span><span class="p">,</span>  <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_series</span>  <span class="o">=</span> <span class="p">[</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span>  <span class="bp">True</span><span class="p">,</span>  <span class="bp">True</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ct</span> <span class="o">=</span> <span class="n">verify</span><span class="o">.</span><span class="n">Contingency2x2</span><span class="o">.</span><span class="n">fromBoolean</span><span class="p">(</span><span class="n">pred_series</span><span class="p">,</span> <span class="n">event_series</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ct</span><span class="o">.</span><span class="n">MatthewsCC</span><span class="p">()</span>
<span class="go">-0.333...</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.PC">
<code class="descname">PC</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.PC" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the Proportion Correct (PC) for the 2x2 contingency table</p>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.POD">
<code class="descname">POD</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.POD" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Probability of Detection, a.k.a. hit rate (ratio of correct forecasts to number of event occurrences)</p>
<dl class="docutils">
<dt>hitrate <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The hit rate of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.POFD">
<code class="descname">POFD</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.POFD" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Probability of False Detection (POFD), a.k.a. False Alarm Rate</p>
<dl class="docutils">
<dt>pofd <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The probability of false detection of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.bias">
<code class="descname">bias</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.bias" title="Permalink to this definition">¶</a></dt>
<dd><p>The frequency bias of the forecast calculated as the ratio of yes forecasts to number of yes events</p>
<p>An unbiased forecast will have bias=1, showing that the number of forecasts is the same
as the number of events. Bias&gt;1 means that more events were forecast than observed (overforecast).</p>
<dl class="docutils">
<dt>bias <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The bias of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.equitableThreat">
<code class="descname">equitableThreat</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.equitableThreat" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Equitable Threat Score (a.k.a. Gilbert Skill Score)</p>
<p>This is a ratio of verification, i.e., the proportion of correct forecasts
after removing correct &#8220;no&#8221; forecasts (or &#8216;true negatives&#8217;).</p>
<dl class="docutils">
<dt>thr <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The threat score of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="classmethod">
<dt id="verify.Contingency2x2.fromBoolean">
<em class="property">classmethod </em><code class="descname">fromBoolean</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.fromBoolean" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a 2x2 contingency table from two boolean input arrays</p>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.heidke">
<code class="descname">heidke</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.heidke" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Heidke Skill Score for the 2x2 contingency table</p>
<p>This is a skill score based on the proportion of correct forecasts referred to
the proportion expected correct by chance.</p>
<dl class="docutils">
<dt>hss <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The Heidke skill score of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.majorityClassFraction">
<code class="descname">majorityClassFraction</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.majorityClassFraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Proportion Correct (a.k.a. &#8220;accuracy&#8221; in machine learning) for majority classifier</p>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.oddsRatio">
<code class="descname">oddsRatio</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.oddsRatio" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the odds ratio for the 2x2 contingency table</p>
<dl class="docutils">
<dt>odds <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The odds ratio for the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.peirce">
<code class="descname">peirce</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.peirce" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Peirce Skill Score for the 2x2 contingency table</p>
<dl class="docutils">
<dt>pss <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The Peirce skill score of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.threat">
<code class="descname">threat</code><span class="sig-paren">(</span><em>ci=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.threat" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Threat Score (a.k.a. critical success index)</p>
<p>This is a ratio of verification, i.e., the proportion of correct forecasts
after removing correct &#8220;no&#8221; forecasts (or &#8216;true negatives&#8217;).</p>
<dl class="docutils">
<dt>thr <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The threat score of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="verify.Contingency2x2.yuleQ">
<code class="descname">yuleQ</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#verify.Contingency2x2.yuleQ" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate Yule&#8217;s Q (odds ratio skill score) for the 2x2 contingency table</p>
<dl class="docutils">
<dt>yule <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Yule&#8217;s Q for the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="verify.ContingencyNxN">
<em class="property">class </em><code class="descclassname">verify.</code><code class="descname">ContingencyNxN</code><a class="headerlink" href="#verify.ContingencyNxN" title="Permalink to this definition">¶</a></dt>
<dd><p>Class to work with NxN contingency tables for forecast verification</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">verify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span> <span class="o">=</span> <span class="n">verify</span><span class="o">.</span><span class="n">ContingencyNxN</span><span class="p">([[</span><span class="mi">28</span><span class="p">,</span><span class="mi">72</span><span class="p">],[</span><span class="mi">23</span><span class="p">,</span><span class="mi">2680</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="go">2803</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">threat</span><span class="p">()</span>
<span class="go">0.22764227642276422</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">heidke</span><span class="p">()</span>
<span class="go">0.35532486145845693</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">peirce</span><span class="p">()</span>
<span class="go">0.52285681714546284</span>
</pre></div>
</div>
<dl class="method">
<dt id="verify.ContingencyNxN.PC">
<code class="descname">PC</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#verify.ContingencyNxN.PC" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the Proportion Correct (PC) for the NxN contingency table</p>
</dd></dl>

<dl class="method">
<dt id="verify.ContingencyNxN.get2x2">
<code class="descname">get2x2</code><span class="sig-paren">(</span><em>category</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.ContingencyNxN.get2x2" title="Permalink to this definition">¶</a></dt>
<dd><p>Get 2x2 sub-table from multicategory contingency table</p>
<p>Goldsmith&#8217;s non-probabilistic forecasts for freezing rain (cat 0), snow (cat 1)
and rain (cat 2). [see Wilks, 1995, p273]</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">verify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span> <span class="o">=</span> <span class="n">verify</span><span class="o">.</span><span class="n">ContingencyNxN</span><span class="p">([[</span><span class="mi">50</span><span class="p">,</span><span class="mi">91</span><span class="p">,</span><span class="mi">71</span><span class="p">],[</span><span class="mi">47</span><span class="p">,</span><span class="mi">2364</span><span class="p">,</span><span class="mi">170</span><span class="p">],[</span><span class="mi">54</span><span class="p">,</span><span class="mi">205</span><span class="p">,</span><span class="mi">3288</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt2</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">get2x2</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">tt2</span><span class="p">)</span>
<span class="go">[[  50  162]</span>
<span class="go"> [ 101 6027]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt2</span><span class="o">.</span><span class="n">bias</span><span class="p">()</span>
<span class="go">1.4039735099337749</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt2</span><span class="o">.</span><span class="n">attrs</span><span class="p">()</span>
<span class="go">{&#39;Bias&#39;: 1.4039735099337749,</span>
<span class="go"> &#39;FAR&#39;: 0.76415094339622647,</span>
<span class="go"> &#39;HeidkeScore&#39;: 0.25474971797571822,</span>
<span class="go"> &#39;POD&#39;: 0.33112582781456956,</span>
<span class="go"> &#39;POFD&#39;: 0.026175472612699952,</span>
<span class="go"> &#39;PeirceScore&#39;: 0.30495035520187008,</span>
<span class="go"> &#39;ThreatScore&#39;: 0.15974440894568689}</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="verify.ContingencyNxN.heidke">
<code class="descname">heidke</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#verify.ContingencyNxN.heidke" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the generalized Heidke Skill Score for the NxN contingency table</p>
<dl class="docutils">
<dt>hss <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The Heidke skill score of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
<p>Goldsmith&#8217;s non-probabilistic forecasts for freezing rain (cat 0), snow (cat 1)
and rain (cat 2). [see Wilks, 1995, p273-274]</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">verify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span> <span class="o">=</span> <span class="n">verify</span><span class="o">.</span><span class="n">ContingencyNxN</span><span class="p">([[</span><span class="mi">50</span><span class="p">,</span><span class="mi">91</span><span class="p">,</span><span class="mi">71</span><span class="p">],[</span><span class="mi">47</span><span class="p">,</span><span class="mi">2364</span><span class="p">,</span><span class="mi">170</span><span class="p">],[</span><span class="mi">54</span><span class="p">,</span><span class="mi">205</span><span class="p">,</span><span class="mi">3288</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">heidke</span><span class="p">()</span>
<span class="go">0.80535269033647217</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="verify.ContingencyNxN.peirce">
<code class="descname">peirce</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#verify.ContingencyNxN.peirce" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the generalized Peirce Skill Score for the NxN contingency table</p>
<dl class="docutils">
<dt>pss <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>The Peirce skill score of the contingency table data
This is also added to the attrs attribute of the table object</dd>
</dl>
<p>Goldsmith&#8217;s non-probabilistic forecasts for freezing rain (cat 0), snow (cat 1)
and rain (cat 2). [see Wilks, 1995, p273-274]</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">verify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span> <span class="o">=</span> <span class="n">verify</span><span class="o">.</span><span class="n">ContingencyNxN</span><span class="p">([[</span><span class="mi">50</span><span class="p">,</span><span class="mi">91</span><span class="p">,</span><span class="mi">71</span><span class="p">],[</span><span class="mi">47</span><span class="p">,</span><span class="mi">2364</span><span class="p">,</span><span class="mi">170</span><span class="p">],[</span><span class="mi">54</span><span class="p">,</span><span class="mi">205</span><span class="p">,</span><span class="mi">3288</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tt</span><span class="o">.</span><span class="n">peirce</span><span class="p">()</span>
<span class="go">0.81071330546125309</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="verify.MASE">
<code class="descclassname">verify.</code><code class="descname">MASE</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.MASE" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean Absolute Scaled Error</p>
</dd></dl>

<dl class="function">
<dt id="verify.RMSE">
<code class="descclassname">verify.</code><code class="descname">RMSE</code><span class="sig-paren">(</span><em>data</em>, <em>climate=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.RMSE" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the root mean squared error of a data set relative to some reference value</p>
<p>The chosen reference can be persistence, a provided climatological mean (scalar)
or a provided climatology (observation vector).</p>
<dl class="docutils">
<dt>data <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>data to calculate mean squared error, default reference is persistence</dd>
</dl>
<dl class="docutils">
<dt>climate: float</dt>
<dd>climatological mean to use as reference value</dd>
</dl>
<dl class="docutils">
<dt>out <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>the root-mean-squared error of the data set relative to the chosen reference</dd>
</dl>
<p>meanSquaredError, meanAbsError</p>
</dd></dl>

<dl class="function">
<dt id="verify.Sn">
<code class="descclassname">verify.</code><code class="descname">Sn</code><span class="sig-paren">(</span><em>data</em>, <em>scale=True</em>, <em>correct=True</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.Sn" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Sn statistic, which is a robust measure of scale.</p>
<p>Sn is more efficient than the median absolute deviation, and is not constructed with the 
assumption of a symmetric distribution, because it does not measure distance from an assumed
central location. To quote RC1993, &#8221;...Sn looks at a typical distance between observations, 
which is still valid at asymmetric distributions.&#8221;</p>
<p>[RC1993] P.J.Rouseeuw and C.Croux, &#8220;Alternatives to the Median Absolute Deviation&#8221;, J. Amer. Stat. Assoc.,
88 (424), pp.1273-1283. Equation 2.1, but note that they use &#8220;low&#8221; and &#8220;high&#8221; medians:
Sn = c * 1.1926 * LOMED_{i} ( HIMED_{j} (<a href="#id3"><span class="problematic" id="id4">|x_i - x_j|</span></a>) )</p>
<p>Note that the implementation of the original formulation is slow for large n. As the original formulation
is identical to using a true median for odd-length series, we do so here automatically to gain a significant
speedup.</p>
<dl class="docutils">
<dt>data <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>data to calculate Sn statistic for</dd>
</dl>
<dl class="docutils">
<dt>Sn <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>the Sn statistic</dd>
</dl>
<p>medAbsDev</p>
</dd></dl>

<dl class="function">
<dt id="verify.absPercError">
<code class="descclassname">verify.</code><code class="descname">absPercError</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.absPercError" title="Permalink to this definition">¶</a></dt>
<dd><p>Absolute percentage error</p>
</dd></dl>

<dl class="function">
<dt id="verify.accuracy">
<code class="descclassname">verify.</code><code class="descname">accuracy</code><span class="sig-paren">(</span><em>data</em>, <em>climate=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.accuracy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="verify.bias">
<code class="descclassname">verify.</code><code class="descname">bias</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale-dependent bias as measured by the mean error</p>
</dd></dl>

<dl class="function">
<dt id="verify.forecastError">
<code class="descclassname">verify.</code><code class="descname">forecastError</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em>, <em>full=True</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.forecastError" title="Permalink to this definition">¶</a></dt>
<dd><p>Error, defined using the sign convention of Jolliffe and Stephenson (Ch. 5)</p>
</dd></dl>

<dl class="function">
<dt id="verify.logAccuracy">
<code class="descclassname">verify.</code><code class="descname">logAccuracy</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em>, <em>base=10</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.logAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Log Accuracy Ratio, defined as log(predicted/observed) or log(predicted)-log(observed)</p>
<p>Using base 2 is computationally much faster, so unless the base is important to interpretation
we recommend using that.</p>
</dd></dl>

<dl class="function">
<dt id="verify.meanAbsError">
<code class="descclassname">verify.</code><code class="descname">meanAbsError</code><span class="sig-paren">(</span><em>data</em>, <em>climate=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.meanAbsError" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the mean absolute error of a data set relative to some reference value</p>
<p>The chosen reference can be persistence, a provided climatological mean (scalar)
or a provided climatology (observation vector).</p>
<dl class="docutils">
<dt>data <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>data to calculate mean squared error, default reference is persistence</dd>
</dl>
<dl class="docutils">
<dt>climate: float</dt>
<dd>climatology to use as reference</dd>
</dl>
<dl class="docutils">
<dt>out <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>the mean absolute error of the data set relative to the chosen reference</dd>
</dl>
<p>medAbsError, meanSquaredError, RMSE</p>
</dd></dl>

<dl class="function">
<dt id="verify.meanPercentageError">
<code class="descclassname">verify.</code><code class="descname">meanPercentageError</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.meanPercentageError" title="Permalink to this definition">¶</a></dt>
<dd><p>Order-dependent bias as measured by the mean percentage error</p>
</dd></dl>

<dl class="function">
<dt id="verify.meanSquaredError">
<code class="descclassname">verify.</code><code class="descname">meanSquaredError</code><span class="sig-paren">(</span><em>data</em>, <em>climate=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.meanSquaredError" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the mean squared error of a data set relative to some reference value</p>
<p>The chosen reference can be persistence, a provided climatological mean (scalar)
or a provided climatology (observation vector).</p>
<dl class="docutils">
<dt>data <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>data to calculate mean squared error, default reference is persistence</dd>
</dl>
<dl class="docutils">
<dt>climate: float</dt>
<dd>climatological mean to use as reference value</dd>
</dl>
<dl class="docutils">
<dt>out <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>the mean-squared-error of the data set relative to the chosen reference</dd>
</dl>
<p>RMSE, meanAbsError</p>
</dd></dl>

<dl class="function">
<dt id="verify.medAbsDev">
<code class="descclassname">verify.</code><code class="descname">medAbsDev</code><span class="sig-paren">(</span><em>series</em>, <em>scale=False</em>, <em>median=False</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.medAbsDev" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the median absolute deviation from the median</p>
</dd></dl>

<dl class="function">
<dt id="verify.medAbsError">
<code class="descclassname">verify.</code><code class="descname">medAbsError</code><span class="sig-paren">(</span><em>data</em>, <em>climate=None</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.medAbsError" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the median absolute error of a data set relative to some reference value</p>
<p>The chosen reference can be persistence, a provided climatological mean (scalar)
or a provided climatology (observation vector).</p>
<dl class="docutils">
<dt>data <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>data to calculate median absolute error, default reference is persistence</dd>
</dl>
<dl class="docutils">
<dt>climate: float</dt>
<dd>climatology to use as reference</dd>
</dl>
<dl class="docutils">
<dt>out <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>the median absolute error of the data set relative to the chosen reference</dd>
</dl>
<p>meanAbsError, meanSquaredError, RMSE</p>
</dd></dl>

<dl class="function">
<dt id="verify.medSymAccuracy">
<code class="descclassname">verify.</code><code class="descname">medSymAccuracy</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em>, <em>mfunc=&lt;function median&gt;</em>, <em>method='log'</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.medSymAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Median Symmetric Accuracy: Scaled measure of accuracy that is not biased to over- or under-predictions.</p>
<p>The accuracy ratio is given by (prediction/observation), to avoid the bias inherent in mean/median percentage error
metrics we use the log of the accuracy ratio (which is symmetric about 0 for changes of the same factor). Specifically,
the Median Symmetric Accuracy is found by calculating the median of the absolute log accuracy, and re-exponentiating
g = exp( median( <a href="#id5"><span class="problematic" id="id6">|ln(pred) - ln(obs)|</span></a> ) )</p>
<p>This can be expressed as a symmetric percentage error by shifting by one unit and multiplying by 100
MSA = 100*(g-1)</p>
<p>It can also be shown that this is identically equivalent to the median unsigned percentage error, where
the unsigned relative error is given by
(y&#8217; - x&#8217;)/x&#8217;
where y&#8217; is always the larger of the (observation, prediction) pair, and x&#8217; is always the smaller.</p>
<p>Reference:
Morley, S.K. (2016), Alternatives to accuracy and bias metrics based on percentage errors for radiation belt
modeling applications, Los Alamos National Laboratory Report, LA-UR-15-24592.</p>
</dd></dl>

<dl class="function">
<dt id="verify.medianLogAccuracy">
<code class="descclassname">verify.</code><code class="descname">medianLogAccuracy</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em>, <em>mfunc=&lt;function median&gt;</em>, <em>base=10</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.medianLogAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Order-dependent bias as measured by the median of the log accuracy ratio</p>
</dd></dl>

<dl class="function">
<dt id="verify.nRMSE">
<code class="descclassname">verify.</code><code class="descname">nRMSE</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.nRMSE" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the normalized root mean squared error of a data set relative to some reference value</p>
<p>The chosen reference can be an observation vector or, a provided climatological mean (scalar). This 
definition is due to Yu and Ridley (2002).</p>
<p>References:
Yu, Y., and A. J. Ridley (2008), Validation of the space weather modeling 
framework using ground-based magnetometers, Space Weather, 6, S05002, 
doi:10.1029/2007SW000345.</p>
<dl class="docutils">
<dt>predicted: array-like</dt>
<dd>predicted data for which to calculate mean squared error</dd>
<dt>observed: float</dt>
<dd>observation vector (or climatological value (scalar)) to use as reference value</dd>
</dl>
<dl class="docutils">
<dt>out <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>the normalized root-mean-squared-error of the data set relative to the observations</dd>
</dl>
<p>RMSE</p>
</dd></dl>

<dl class="function">
<dt id="verify.normSn">
<code class="descclassname">verify.</code><code class="descname">normSn</code><span class="sig-paren">(</span><em>data</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.normSn" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the normalized Sn statistic, a scaled measure of spread.</p>
<p>We here scale the Sn estimator by the median, giving a non-symmetric alternative
to the robust coefficient of variation (rCV).</p>
<dl class="docutils">
<dt>data <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd>data to calculate normSn statistic for</dd>
</dl>
<dl class="docutils">
<dt>normSn <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>the normalized Sn statistic</dd>
</dl>
<p>rCV</p>
</dd></dl>

<dl class="function">
<dt id="verify.percBetter">
<code class="descclassname">verify.</code><code class="descname">percBetter</code><span class="sig-paren">(</span><em>predict1</em>, <em>predict2</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.percBetter" title="Permalink to this definition">¶</a></dt>
<dd><p>The percentage of cases when method A was closer to actual than method B</p>
<p>For example, if we want to know whether a new forecast performs better than a reference
forecast...</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">verify</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p_ref</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.5</span><span class="p">]</span><span class="o">*</span><span class="mi">6</span> <span class="c1">#mean prediction</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p_good</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">]</span> <span class="c1">#&quot;good&quot; model prediction</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">verify</span><span class="o">.</span><span class="n">percBetter</span><span class="p">(</span><span class="n">p_good</span><span class="p">,</span> <span class="n">p_ref</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="go">66.66666666666666</span>
</pre></div>
</div>
<p>That is, two-thirds (66.67%) of the predictions have a lower absolute error in p_good than in
p_ref.</p>
</dd></dl>

<dl class="function">
<dt id="verify.percError">
<code class="descclassname">verify.</code><code class="descname">percError</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.percError" title="Permalink to this definition">¶</a></dt>
<dd><p>Percentage Error</p>
</dd></dl>

<dl class="function">
<dt id="verify.rCV">
<code class="descclassname">verify.</code><code class="descname">rCV</code><span class="sig-paren">(</span><em>predicted</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.rCV" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the &#8220;robust coefficient of variation&#8221;, i.e. median absolute deviation divided by the median</p>
<p>By analogy with the coefficient of variation, which is the standard deviation divided by the mean, rCV
gives the median absolute deviation (aka rSD) divided by the median, thereby providing a scaled measure
of precision/spread.</p>
</dd></dl>

<dl class="function">
<dt id="verify.rSD">
<code class="descclassname">verify.</code><code class="descname">rSD</code><span class="sig-paren">(</span><em>predicted</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.rSD" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the &#8220;robust standard deviation&#8221;, i.e. the median absolute deviation times a correction factor</p>
<p>The median absolute deviation (medAbsDev) scaled by a factor of 1.4826 recovers the standard deviation when
applied to a normal distribution. However, unlike the standard deviation the medAbsDev has a high breakdown 
point and is therefore considered a robust estimator.</p>
</dd></dl>

<dl class="function">
<dt id="verify.scaledAccuracy">
<code class="descclassname">verify.</code><code class="descname">scaledAccuracy</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.scaledAccuracy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="verify.scaledError">
<code class="descclassname">verify.</code><code class="descname">scaledError</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.scaledError" title="Permalink to this definition">¶</a></dt>
<dd><p>Scaled errors, see Hyndman and Koehler (2006)</p>
<p>References:
R.J. Hyndman and A.B. Koehler, Another look at measures of forecast 
accuracy, Intl. J. Forecasting, 22, pp. 679-688, 2006.</p>
</dd></dl>

<dl class="function">
<dt id="verify.skill">
<code class="descclassname">verify.</code><code class="descname">skill</code><span class="sig-paren">(</span><em>A_data</em>, <em>A_ref</em>, <em>A_perf=0</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.skill" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic forecast skill score formulation for quantification of forecast improvement</p>
<p>See section 7.1.4 of Wilks [2006] (Statistical methods in the atmospheric sciences) for
details.</p>
<dl class="docutils">
<dt>A_data <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Accuracy measure of data set</dd>
<dt>A_ref <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Accuracy measure for reference forecast</dd>
<dt>A_perf <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Accuracy measure for &#8220;perfect forecast&#8221; (Default = 0)</dd>
</dl>
<dl class="docutils">
<dt>out <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Forecast skill for the given forecast, relative to the reference, using the chosen accuracy measure</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="verify.symmetricSignedBias">
<code class="descclassname">verify.</code><code class="descname">symmetricSignedBias</code><span class="sig-paren">(</span><em>predicted</em>, <em>observed</em><span class="sig-paren">)</span><a class="headerlink" href="#verify.symmetricSignedBias" title="Permalink to this definition">¶</a></dt>
<dd><p>Symmetric signed bias, expressed as a percentage</p>
</dd></dl>

</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">PyForecastTools - Model Validation and Forecast Verification</a><ul>
<li><a class="reference internal" href="#verify-core-metrics-and-classes">Verify - Core metrics and classes</a><ul>
<li><a class="reference internal" href="#metrics">Metrics</a></li>
<li><a class="reference internal" href="#contingency-tables">Contingency Tables</a></li>
<li><a class="reference internal" href="#module-verify">Function/Class Documentation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">PyForecastTools documentation</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/verify.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Los Alamos National Security, LLC.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.3.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.7</a>
      
      |
      <a href="_sources/verify.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>